{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Machine Learning Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification-Neural-Network\n",
    "Questions:\n",
    "What is in the audio books dataset?\n",
    "what did you set out to do with the dataset?\n",
    "Did you achieve your initial goal?\n",
    "How did neural nettwork help with your task?\n",
    "why do you think neural nettwork help with your task?\n",
    "why do you think neural network was the best choice for this task?\n",
    "\n",
    "Data Description:\n",
    "This is a data of audio books store which only sells the audio book online. Each person in the data set has atleast purchased the audio once. Our objective is to predict whether the customer will buy the audiobook again or not. \\\n",
    "The variables(column names) are\n",
    "ID : each customer has its own ID,\\\n",
    "Book_length_min_overall: purchase: sum of length of purchase,\\\n",
    "Book_length_min_average: average sum of length of purchase,\\\n",
    "Price_overall: same like above two fields,\\\n",
    ",Price_avg: same as above description,\\\n",
    "Review: review given by customer or not if given 1 else 0,\\\n",
    "Review on 10/10: if review is 1 then the reviewed value for review 0 we take an average of review value and we fill up the shell for empty review,\\\n",
    "Minutes_listened: total listened minutes,\\\n",
    "Completion:it is the ratio of total_minutes_listened and book length overall,\\\n",
    "Support_request: it is whether user ask for support or not?,\\\n",
    "Last_visited_minus_purchase_date: The bigger the difference the better the user's engagement,\\\n",
    "and Targets: this is the targets(output in boolean value)\\\n",
    "\n",
    "The input data represents the two year of people engagements. We are doing the supervised learning so we need targets; tagrets 1 if a person converted, targets 0 if a person didn't converted\\\n",
    "Now the extra six months of data after the two  year period are also added to check if a user were converted or not. .i.e if a person bought another book or not. if they are converted then target is 1 else it is zero\n",
    "So now we are creating a ML algorith that can predict whether a customer will buy a book again or not.\n",
    "So this is a classification problem with two class won't buy and will buy represented by zeros and one\\\n",
    "\\\n",
    "Note: our inputs are all the variables of the csv file except for the first and the last column .i.e ID and Target\\\n",
    "\n",
    "For data preprocessing we have used these three proccesses:\n",
    "* Balance the dataset\n",
    "* Divide the data set into training validation and test\n",
    "* Saving the data in tensorflow friendly format\n",
    "\n",
    "we have used sklearn capabilities for standardizing the inputs by doing this we have gain the accuracy by 10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# we use sklern for standardization for higher accuracy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading except for last and first variables\n",
    "raw_csv_data = np.loadtxt('Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "# input except first and last column\n",
    "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
    "\n",
    "# last column of csv\n",
    "targets_all = raw_csv_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the dataset\n",
    "Since there are many items for target = 0 so we need to balance the dataset\n",
    "* We will count the number of targets that are 1s\n",
    "* We will keep as many 0s as 1s(we have deleted others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_targets = int(np.sum(targets_all))\n",
    "zero_targets_counter = 0\n",
    "indices_to_remove = []\n",
    "\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i] ==0:\n",
    "        zero_targets_counter += 1\n",
    "        if zero_targets_counter > num_one_targets:\n",
    "            indices_to_remove.append(i)\n",
    "            \n",
    "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis = 0)\n",
    "targets_equal_priors = np.delete (targets_all, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized(Scale) the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffel the data\n",
    "keeping the same information in different order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_targets = targets_equal_priors[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data for training,validating and testing\n",
    "I'm using 0.80,0.10,0.10 ratio split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794.0 3579 0.501257334450964\n",
      "227.0 447 0.5078299776286354\n",
      "216.0 448 0.48214285714285715\n"
     ]
    }
   ],
   "source": [
    "samples_count = shuffled_inputs.shape[0]\n",
    "\n",
    "train_samples_count = int(0.8*samples_count)\n",
    "validation_samples_count = int(0.1*samples_count)\n",
    "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
    "\n",
    "train_inputs = shuffled_inputs[:train_samples_count]\n",
    "train_targets = shuffled_targets[:train_samples_count]\n",
    "\n",
    "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count+validation_samples_count]\n",
    "validation_targets = shuffled_targets[train_samples_count:train_samples_count+validation_samples_count]\n",
    "\n",
    "test_inputs = shuffled_inputs[train_samples_count+validation_samples_count:]\n",
    "test_targets = shuffled_targets[train_samples_count+validation_samples_count:]\n",
    "\n",
    "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
    "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
    "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow friendly dataset\n",
    "saving in .npz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobooks_data_train',inputs = train_inputs, targets = train_targets)\n",
    "np.savez('Audiobooks_data_validation', inputs = validation_inputs, targets = validation_targets)\n",
    "np.savez('Audiobooks_data_test',inputs = test_inputs, targets = test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed the data preprocess competely for two class data.\\\n",
    "This code can be  generalized for all type of data preprocessing for any dataset with two classes \\\n",
    "Only we need two play around with balancing section if we have more classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imageee.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input is given from csv file and we have two possible outcome .i.e target =1 or target = 0\\\n",
    "we are assuming two hidden layer of 50 units on each hidden layer\n",
    "![](img.png)\n",
    "\n",
    "* Figure Description\n",
    "The above figure is the network of our model. There are 10 inputs and only 2 outputs. \\\n",
    "Input data is taken from csv file and for two output; one is for target 1 and second is for target 0. In the dataset 1 and 0 are the two types of tems for the classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs = npz['inputs'].astype(np.float)\n",
    "validation_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs = npz['inputs'].astype(np.float)\n",
    "test_targets = npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "outline, optimizer, loss, early stopping and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.5618 - accuracy: 0.7868 - val_loss: 0.4206 - val_accuracy: 0.8881\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.3702 - accuracy: 0.8757 - val_loss: 0.3026 - val_accuracy: 0.8971\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.3190 - accuracy: 0.8849 - val_loss: 0.2735 - val_accuracy: 0.9105\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.2994 - accuracy: 0.8902 - val_loss: 0.2649 - val_accuracy: 0.9150\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.2864 - accuracy: 0.8938 - val_loss: 0.2460 - val_accuracy: 0.9128\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.2747 - accuracy: 0.8977 - val_loss: 0.2411 - val_accuracy: 0.9217\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.2664 - accuracy: 0.9003 - val_loss: 0.2351 - val_accuracy: 0.9217\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.2588 - accuracy: 0.9019 - val_loss: 0.2251 - val_accuracy: 0.9239\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.2562 - accuracy: 0.9033 - val_loss: 0.2248 - val_accuracy: 0.9217\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.2502 - accuracy: 0.9056 - val_loss: 0.2263 - val_accuracy: 0.9239\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.2468 - accuracy: 0.9072 - val_loss: 0.2228 - val_accuracy: 0.9217\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.2460 - accuracy: 0.9084 - val_loss: 0.2213 - val_accuracy: 0.9262\n",
      "Epoch 13/100\n",
      "36/36 - 1s - loss: 0.2416 - accuracy: 0.9058 - val_loss: 0.2198 - val_accuracy: 0.9262\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.2407 - accuracy: 0.9098 - val_loss: 0.2224 - val_accuracy: 0.9262\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.2379 - accuracy: 0.9072 - val_loss: 0.2220 - val_accuracy: 0.9284\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.2375 - accuracy: 0.9114 - val_loss: 0.2172 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.2350 - accuracy: 0.9089 - val_loss: 0.2191 - val_accuracy: 0.9217\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.2348 - accuracy: 0.9117 - val_loss: 0.2303 - val_accuracy: 0.9262\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.2348 - accuracy: 0.9106 - val_loss: 0.2127 - val_accuracy: 0.9284\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.2299 - accuracy: 0.9111 - val_loss: 0.2171 - val_accuracy: 0.9262\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.2307 - accuracy: 0.9131 - val_loss: 0.2099 - val_accuracy: 0.9306\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.2287 - accuracy: 0.9134 - val_loss: 0.2256 - val_accuracy: 0.9284\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.2293 - accuracy: 0.9131 - val_loss: 0.2186 - val_accuracy: 0.9217\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.2267 - accuracy: 0.9128 - val_loss: 0.2109 - val_accuracy: 0.9262\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.2259 - accuracy: 0.9145 - val_loss: 0.2116 - val_accuracy: 0.9262\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.2246 - accuracy: 0.9151 - val_loss: 0.2125 - val_accuracy: 0.9239\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.2258 - accuracy: 0.9137 - val_loss: 0.2052 - val_accuracy: 0.9284\n",
      "Epoch 28/100\n",
      "36/36 - 0s - loss: 0.2251 - accuracy: 0.9153 - val_loss: 0.2059 - val_accuracy: 0.9329\n",
      "Epoch 29/100\n",
      "36/36 - 0s - loss: 0.2219 - accuracy: 0.9142 - val_loss: 0.2140 - val_accuracy: 0.9217\n",
      "Epoch 30/100\n",
      "36/36 - 0s - loss: 0.2229 - accuracy: 0.9159 - val_loss: 0.2097 - val_accuracy: 0.9284\n",
      "Epoch 31/100\n",
      "36/36 - 0s - loss: 0.2230 - accuracy: 0.9153 - val_loss: 0.2116 - val_accuracy: 0.9262\n",
      "Epoch 32/100\n",
      "36/36 - 0s - loss: 0.2239 - accuracy: 0.9142 - val_loss: 0.2108 - val_accuracy: 0.9306\n",
      "Epoch 33/100\n",
      "36/36 - 0s - loss: 0.2223 - accuracy: 0.9162 - val_loss: 0.2042 - val_accuracy: 0.9329\n",
      "Epoch 34/100\n",
      "36/36 - 0s - loss: 0.2213 - accuracy: 0.9176 - val_loss: 0.2091 - val_accuracy: 0.9329\n",
      "Epoch 35/100\n",
      "36/36 - 0s - loss: 0.2207 - accuracy: 0.9170 - val_loss: 0.2096 - val_accuracy: 0.9239\n",
      "Epoch 36/100\n",
      "36/36 - 0s - loss: 0.2207 - accuracy: 0.9156 - val_loss: 0.2155 - val_accuracy: 0.9306\n",
      "Epoch 37/100\n",
      "36/36 - 0s - loss: 0.2199 - accuracy: 0.9162 - val_loss: 0.2069 - val_accuracy: 0.9329\n",
      "Epoch 38/100\n",
      "36/36 - 0s - loss: 0.2197 - accuracy: 0.9153 - val_loss: 0.2105 - val_accuracy: 0.9284\n",
      "Epoch 39/100\n",
      "36/36 - 0s - loss: 0.2213 - accuracy: 0.9173 - val_loss: 0.2036 - val_accuracy: 0.9329\n",
      "Epoch 40/100\n",
      "36/36 - 0s - loss: 0.2171 - accuracy: 0.9179 - val_loss: 0.2078 - val_accuracy: 0.9306\n",
      "Epoch 41/100\n",
      "36/36 - 0s - loss: 0.2149 - accuracy: 0.9173 - val_loss: 0.2001 - val_accuracy: 0.9351\n",
      "Epoch 42/100\n",
      "36/36 - 0s - loss: 0.2189 - accuracy: 0.9159 - val_loss: 0.2024 - val_accuracy: 0.9351\n",
      "Epoch 43/100\n",
      "36/36 - 0s - loss: 0.2160 - accuracy: 0.9181 - val_loss: 0.2013 - val_accuracy: 0.9351\n",
      "Epoch 44/100\n",
      "36/36 - 0s - loss: 0.2183 - accuracy: 0.9179 - val_loss: 0.2094 - val_accuracy: 0.9351\n",
      "Epoch 45/100\n",
      "36/36 - 0s - loss: 0.2182 - accuracy: 0.9173 - val_loss: 0.2056 - val_accuracy: 0.9306\n",
      "Epoch 46/100\n",
      "36/36 - 0s - loss: 0.2173 - accuracy: 0.9173 - val_loss: 0.2071 - val_accuracy: 0.9351\n",
      "Epoch 47/100\n",
      "36/36 - 0s - loss: 0.2163 - accuracy: 0.9159 - val_loss: 0.2015 - val_accuracy: 0.9329\n",
      "Epoch 48/100\n",
      "36/36 - 0s - loss: 0.2138 - accuracy: 0.9190 - val_loss: 0.2064 - val_accuracy: 0.9351\n",
      "Epoch 49/100\n",
      "36/36 - 0s - loss: 0.2142 - accuracy: 0.9201 - val_loss: 0.2062 - val_accuracy: 0.9329\n",
      "Epoch 50/100\n",
      "36/36 - 0s - loss: 0.2132 - accuracy: 0.9193 - val_loss: 0.2077 - val_accuracy: 0.9351\n",
      "Epoch 51/100\n",
      "36/36 - 0s - loss: 0.2147 - accuracy: 0.9184 - val_loss: 0.2083 - val_accuracy: 0.9284\n",
      "Epoch 52/100\n",
      "36/36 - 0s - loss: 0.2179 - accuracy: 0.9195 - val_loss: 0.2184 - val_accuracy: 0.9284\n",
      "Epoch 53/100\n",
      "36/36 - 0s - loss: 0.2142 - accuracy: 0.9176 - val_loss: 0.2130 - val_accuracy: 0.9306\n",
      "Epoch 54/100\n",
      "36/36 - 0s - loss: 0.2148 - accuracy: 0.9193 - val_loss: 0.2076 - val_accuracy: 0.9329\n",
      "Epoch 55/100\n",
      "36/36 - 0s - loss: 0.2128 - accuracy: 0.9170 - val_loss: 0.2117 - val_accuracy: 0.9284\n",
      "Epoch 56/100\n",
      "36/36 - 0s - loss: 0.2122 - accuracy: 0.9198 - val_loss: 0.2078 - val_accuracy: 0.9329\n",
      "Epoch 57/100\n",
      "36/36 - 0s - loss: 0.2132 - accuracy: 0.9190 - val_loss: 0.2062 - val_accuracy: 0.9329\n",
      "Epoch 58/100\n",
      "36/36 - 0s - loss: 0.2134 - accuracy: 0.9181 - val_loss: 0.2136 - val_accuracy: 0.9329\n",
      "Epoch 59/100\n",
      "36/36 - 0s - loss: 0.2107 - accuracy: 0.9204 - val_loss: 0.2103 - val_accuracy: 0.9351\n",
      "Epoch 60/100\n",
      "36/36 - 0s - loss: 0.2127 - accuracy: 0.9187 - val_loss: 0.2067 - val_accuracy: 0.9306\n",
      "Epoch 61/100\n",
      "36/36 - 0s - loss: 0.2143 - accuracy: 0.9204 - val_loss: 0.2111 - val_accuracy: 0.9329\n",
      "Epoch 62/100\n",
      "36/36 - 0s - loss: 0.2108 - accuracy: 0.9204 - val_loss: 0.2112 - val_accuracy: 0.9306\n",
      "Epoch 63/100\n",
      "36/36 - 0s - loss: 0.2105 - accuracy: 0.9223 - val_loss: 0.2029 - val_accuracy: 0.9351\n",
      "Epoch 64/100\n",
      "36/36 - 0s - loss: 0.2107 - accuracy: 0.9201 - val_loss: 0.2106 - val_accuracy: 0.9262\n",
      "Epoch 65/100\n",
      "36/36 - 0s - loss: 0.2110 - accuracy: 0.9218 - val_loss: 0.2067 - val_accuracy: 0.9329\n",
      "Epoch 66/100\n",
      "36/36 - 0s - loss: 0.2096 - accuracy: 0.9201 - val_loss: 0.2034 - val_accuracy: 0.9329\n",
      "Epoch 67/100\n",
      "36/36 - 0s - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.2068 - val_accuracy: 0.9329\n",
      "Epoch 68/100\n",
      "36/36 - 0s - loss: 0.2111 - accuracy: 0.9212 - val_loss: 0.2064 - val_accuracy: 0.9329\n",
      "Epoch 69/100\n",
      "36/36 - 0s - loss: 0.2091 - accuracy: 0.9215 - val_loss: 0.2050 - val_accuracy: 0.9329\n",
      "Epoch 70/100\n",
      "36/36 - 0s - loss: 0.2088 - accuracy: 0.9212 - val_loss: 0.2064 - val_accuracy: 0.9329\n",
      "Epoch 71/100\n",
      "36/36 - 0s - loss: 0.2108 - accuracy: 0.9223 - val_loss: 0.2127 - val_accuracy: 0.9306\n",
      "Epoch 72/100\n",
      "36/36 - 0s - loss: 0.2075 - accuracy: 0.9212 - val_loss: 0.2128 - val_accuracy: 0.9351\n",
      "Epoch 73/100\n",
      "36/36 - 0s - loss: 0.2092 - accuracy: 0.9220 - val_loss: 0.2123 - val_accuracy: 0.9329\n",
      "Epoch 74/100\n",
      "36/36 - 0s - loss: 0.2087 - accuracy: 0.9223 - val_loss: 0.2068 - val_accuracy: 0.9351\n",
      "Epoch 75/100\n",
      "36/36 - 0s - loss: 0.2077 - accuracy: 0.9215 - val_loss: 0.2144 - val_accuracy: 0.9351\n",
      "Epoch 76/100\n",
      "36/36 - 0s - loss: 0.2071 - accuracy: 0.9215 - val_loss: 0.2079 - val_accuracy: 0.9329\n",
      "Epoch 77/100\n",
      "36/36 - 0s - loss: 0.2092 - accuracy: 0.9209 - val_loss: 0.2077 - val_accuracy: 0.9351\n",
      "Epoch 78/100\n",
      "36/36 - 0s - loss: 0.2099 - accuracy: 0.9209 - val_loss: 0.2068 - val_accuracy: 0.9329\n",
      "Epoch 79/100\n",
      "36/36 - 0s - loss: 0.2060 - accuracy: 0.9232 - val_loss: 0.2133 - val_accuracy: 0.9351\n",
      "Epoch 80/100\n",
      "36/36 - 0s - loss: 0.2100 - accuracy: 0.9223 - val_loss: 0.2048 - val_accuracy: 0.9329\n",
      "Epoch 81/100\n",
      "36/36 - 0s - loss: 0.2065 - accuracy: 0.9220 - val_loss: 0.2046 - val_accuracy: 0.9351\n",
      "Epoch 82/100\n",
      "36/36 - 0s - loss: 0.2044 - accuracy: 0.9232 - val_loss: 0.2141 - val_accuracy: 0.9306\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 0s - loss: 0.2068 - accuracy: 0.9218 - val_loss: 0.2221 - val_accuracy: 0.9217\n",
      "Epoch 84/100\n",
      "36/36 - 0s - loss: 0.2133 - accuracy: 0.9190 - val_loss: 0.2165 - val_accuracy: 0.9329\n",
      "Epoch 85/100\n",
      "36/36 - 0s - loss: 0.2060 - accuracy: 0.9226 - val_loss: 0.2063 - val_accuracy: 0.9329\n",
      "Epoch 86/100\n",
      "36/36 - 0s - loss: 0.2029 - accuracy: 0.9237 - val_loss: 0.2182 - val_accuracy: 0.9306\n",
      "Epoch 87/100\n",
      "36/36 - 0s - loss: 0.2049 - accuracy: 0.9237 - val_loss: 0.2161 - val_accuracy: 0.9329\n",
      "Epoch 88/100\n",
      "36/36 - 0s - loss: 0.2042 - accuracy: 0.9223 - val_loss: 0.2070 - val_accuracy: 0.9351\n",
      "Epoch 89/100\n",
      "36/36 - 0s - loss: 0.2069 - accuracy: 0.9234 - val_loss: 0.2063 - val_accuracy: 0.9329\n",
      "Epoch 90/100\n",
      "36/36 - 0s - loss: 0.2036 - accuracy: 0.9240 - val_loss: 0.2182 - val_accuracy: 0.9306\n",
      "Epoch 91/100\n",
      "36/36 - 0s - loss: 0.2051 - accuracy: 0.9232 - val_loss: 0.2060 - val_accuracy: 0.9329\n",
      "Epoch 92/100\n",
      "36/36 - 0s - loss: 0.2053 - accuracy: 0.9226 - val_loss: 0.2189 - val_accuracy: 0.9284\n",
      "Epoch 93/100\n",
      "36/36 - 0s - loss: 0.2041 - accuracy: 0.9218 - val_loss: 0.2132 - val_accuracy: 0.9284\n",
      "Epoch 94/100\n",
      "36/36 - 0s - loss: 0.2041 - accuracy: 0.9234 - val_loss: 0.2141 - val_accuracy: 0.9329\n",
      "Epoch 95/100\n",
      "36/36 - 0s - loss: 0.2051 - accuracy: 0.9232 - val_loss: 0.2236 - val_accuracy: 0.9329\n",
      "Epoch 96/100\n",
      "36/36 - 0s - loss: 0.2055 - accuracy: 0.9223 - val_loss: 0.2202 - val_accuracy: 0.9329\n",
      "Epoch 97/100\n",
      "36/36 - 0s - loss: 0.2076 - accuracy: 0.9195 - val_loss: 0.2225 - val_accuracy: 0.9217\n",
      "Epoch 98/100\n",
      "36/36 - 0s - loss: 0.2063 - accuracy: 0.9240 - val_loss: 0.2152 - val_accuracy: 0.9306\n",
      "Epoch 99/100\n",
      "36/36 - 0s - loss: 0.2038 - accuracy: 0.9229 - val_loss: 0.2192 - val_accuracy: 0.9239\n",
      "Epoch 100/100\n",
      "36/36 - 0s - loss: 0.2041 - accuracy: 0.9206 - val_loss: 0.2252 - val_accuracy: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f83b6501850>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation='softmax')   \n",
    "                            ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 100\n",
    "\n",
    "model.fit(train_inputs,\n",
    "          train_targets,\n",
    "          batch_size = batch_size,\n",
    "          epochs = max_epochs,\n",
    "          validation_data = (validation_inputs,validation_targets),\n",
    "          verbose = 2\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Accuracy so chance of overfitting \\\n",
    "Looking into the val_loss it gets increase somewhere between so no constant \n",
    "We have overfitted our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2862 - accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.29. Test accuracy: 89.29%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the initial model and hyperparameters , the final test accuracy should be roughly around 89%.\n",
    "\n",
    "Each time the code is rerun, we get a different accuracy because each training is different.\n",
    "\n",
    "We have intentionally reached a suboptimal solution, so we can have space to build on it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
